1
00:00:08,124 --> 00:00:10,742
15년 정도 전부터 워크스테이션과 고사양 개인 컴퓨터들은
2
00:00:10,742 --> 00:00:14,749
디지털 오디오를 쉽게 다룰 만큼 강력해졌습니다.
3
00:00:14,749 --> 00:00:17,470
값비싼 특수 목적용 하드웨어 없이 좋은 워크스테이션으로
4
00:00:17,470 --> 00:00:21,643
압축되지 않은 원본 비디오를 다룰 수 있게 된 것은 약 5년 정도 전부터입니다.
5
00:00:21,643 --> 00:00:25,400
하지만 최근들어 저렴한 가정용 PC조차도 큰 노력 없이
6
00:00:25,400 --> 00:00:28,092
원본 비디오를 전달할 수 있는 CPU와 저장장치를
7
00:00:28,092 --> 00:00:30,479
갖고 있습니다.
8
00:00:30,479 --> 00:00:33,579
따라서 이제 모두가 이러한 저렴한 하드웨어를 사용하는 만큼,
9
00:00:33,579 --> 00:00:36,651
당연하게도 많은 사람들이 디지털 미디어로 재미있는 것을 하고 싶어합니다.
10
00:00:36,651 --> 00:00:39,908
특히 스트리밍을요.
11
00:00:39,908 --> 00:00:44,017
유튜브는 최초의 거대한 성공이었고, 모두가 유튜브에서 뭔가 하고 싶어합니다.
12
00:00:44,017 --> 00:00:47,413
아주 좋아요! 이것들은 매우 재미있으니까요!
13
00:00:48,250 --> 00:00:51,179
디지털 미디어의 소비자를 찾는 것은 전혀 문제가 아닙니다.
14
00:00:51,179 --> 00:00:54,649
하지만 여기서는, 저는 여러 가지를 탐구하고, 만들고,
15
00:00:54,649 --> 00:00:57,869
기술을 발전시키는 엔지니어들, 수학자들, 해커들을
16
00:00:57,869 --> 00:01:01,302
언급하고 싶습니다.
17
00:01:01,302 --> 00:01:03,282
제 가슴속에 있는 사람들을 말이지요.
18
00:01:04,250 --> 00:01:08,723
디지털 미디어, 특히 정보 압축은 컴퓨터 과학 분야에서 다른 것들보다 훨씬 어려운
19
00:01:08,723 --> 00:01:12,822
굉장히 중요한 것으로 인식됩니다.
20
00:01:12,822 --> 00:01:15,700
이 분야의 거대 기업은 그런 인식을 전혀 신경쓰지 않습니다.
21
00:01:15,700 --> 00:01:19,734
그 인식은 그들이 갖고 있는 위태로운 숫자의 기본 특허들을 정당화할 뿐입니다.
22
00:01:19,734 --> 00:01:23,870
그들은 그들의 미디어 연구자들이 최고 중 최고이며,
23
00:01:23,870 --> 00:01:27,738
다른 사람들보다 훨씬 똑똑하여 그들의 번뜩이는 생각들은
24
00:01:27,738 --> 00:01:29,903
일반인들이 이해할 수 없다는 이미지를 좋아합니다.
25
00:01:30,625 --> 00:01:33,716
그건 허튼소리에요.
26
00:01:35,205 --> 00:01:38,900
디지털 오디오, 비디오, 스트리밍, 정보 압축은
27
00:01:38,900 --> 00:01:42,738
끝없는 깊고 자극적인 정신적 도전을 제공합니다.
28
00:01:42,738 --> 00:01:44,662
다른 모든 분야가 그러듯이요.
29
00:01:44,662 --> 00:01:47,929
소수의 사람들많이 관여해 왔기에 어렵고 잘난 분야 같아 보이긴 합니다.
30
00:01:47,929 --> 00:01:51,223
얼마 안 되는 사람들만이 참여해 온 것은 그 얼마 안 되는 사람들만이
31
00:01:51,223 --> 00:01:54,665
이 분야의 연구가 요구하는 비싼 특수 목적 장비를 구입할 수 있었기 때문입니다.
32
00:01:54,665 --> 00:01:58,792
하지만 요즘은, 이 비디오를 보는 거의 모든 사람들은
33
00:01:58,792 --> 00:02:03,317
저렴하고, 다목적이면서도 큰 장난감들을 갖고 놀만큼 강력한 컴퓨터를 갖고 있죠.
34
00:02:05,926 --> 00:02:11,108
오늘날, HTML5와 브라우저, 비디오를 둘러싼,
35
00:02:11,108 --> 00:02:13,671
오픈소스 진영과 폐쇄 진영의 싸움이 진행되고 있습니다.
36
00:02:13,671 --> 00:02:17,048
이제 우리도 참여할 기회가 온 것이죠.
37
00:02:17,048 --> 00:02:20,000
그 시작으로 가장 좋은 것은 지금 우리가 갖고 있는 기술들을
38
00:02:20,000 --> 00:02:22,619
이해하는 것입니다.
39
00:02:23,500 --> 00:02:25,071
이것은 개론, 즉 소개입니다.
40
00:02:25,071 --> 00:02:28,180
개론이기 때문에, 매우 많은 세세한 부분들은 대충 넘어가겠습니다.
41
00:02:28,180 --> 00:02:30,882
그래야 큰 그림 전체를 보기 쉬울 테니까요.
42
00:02:30,882 --> 00:02:33,908
지금 당장은, 꽤 많은 사람들에게 제가 다루는 것들이
43
00:02:33,908 --> 00:02:36,378
이미 익숙할 것입니다.
44
00:02:36,378 --> 00:02:39,293
하지만, 이 모든 것들이 새로운 분들께는 제가 너무 빠를 수도 있지요.
45
00:02:39,293 --> 00:02:44,558
그러니 이 모든 게 새로워 보여도 긴장하지 마세요.
46
00:02:44,558 --> 00:02:48,629
중요한 것은 당신의 상상력을 발휘할 수 있는 아이디어를 찾아내는 것입니다.
47
00:02:48,629 --> 00:02:52,497
특히 그런 아이디어에 대한 용어들에 집중하세요.
48
00:02:52,479 --> 00:02:56,078
왜냐하면 그 단어들로 구글과 위키피디아에서
49
00:02:56,078 --> 00:02:57,753
더 깊이 찾아볼 수 있으니까요.
50
00:02:57,753 --> 00:03:00,094
그러니, 더 이상 야단법석 떨지 않고,
51
00:03:00,094 --> 00:03:03,351
새로운 취미에 발을 들이신 것을 환영하겠습니다.
52
00:03:10,291 --> 00:03:13,030
소리라는 것은 공기의 압력이 파동 형태로 전달되는 것인데,
53
00:03:13,030 --> 00:03:16,981
연못에 조약돌을 던지면 잔물결이 퍼져나가듯이 소리도 그렇게 그 원천으로부터 퍼져나갑니다.
54
00:03:16,981 --> 00:03:19,489
그런 의미에서 마이크나 사람의 귀는
55
00:03:19,489 --> 00:03:22,876
그 압력의 잔물결을 전기 신호로 바꿉니다.
56
00:03:22,876 --> 00:03:25,800
그래요, 이건 중학교 과학 시간에 배우는 것이고 모두가 기억하시겠지요.
57
00:03:25,800 --> 00:03:26,771
계속합시다.
58
00:03:27,465 --> 00:03:32,527
오디오 신호는 1차원 함수이기 때문에 시간 변화에 대해 바뀌는 변수는 하나입니다.
59
00:03:32,527 --> 00:03:34,248
우리가 조금 더 깊이 살펴보면
60
00:03:36,450 --> 00:03:38,190
좀 더 이해하기 쉽겠죠.
61
00:03:38,190 --> 00:03:40,688
이 신호의 다른 측면들도 중요합니다.
62
00:03:40,688 --> 00:03:43,418
이 신호는 연속적인 변수 값과 시간을 가집니다.
63
00:03:43,418 --> 00:03:46,813
이는, 어떤 특정 시간에 어떤 실수 값을 가진다는 뜻이고,
64
00:03:46,813 --> 00:03:50,228
그 값들은 시간상 모든 지점에서 부드럽게 바뀝니다.
65
00:03:50,228 --> 00:03:52,439
얼마나 우리가 확대해서 보든
66
00:03:54,068 --> 00:03:58,510 
불연속적이거나, 갑자기 튀는 값이나, 불연속적인 단계나 
67
00:03:58,510 --> 00:04:01,285
신호가 없어지는 지점은 없습니다.
68
00:04:03,247 --> 00:04:08,475
모든 지점에서 값이 정의됩니다. 고전적인 연속 수학이 이 신호들에 잘 적용됩니다.
69
00:04:11,001 --> 00:04:15,378
반대로, 디지털 신호는 값과 시간에 대해서 불연속적입니다.
70
00:04:15,378 --> 00:04:19,107
펄스 코드 변조(PCM)라고 불리는 가장 간단하고 공통적인 시스템에서는,
71
00:04:19,107 --> 00:04:24,058
정해져 있는 가능한 값들 중 하나가 일정 단위로 떨어져 있는 시간의 특정 지점에서의
72
00:04:24,058 --> 00:04:30,165
그 신호의 값을 나타냅니다. 최종적인 결과는 정수의 흐름(나열)입니다.
73
00:04:30,674 --> 00:04:35,309
Now this looks an awful lot like this.  
이건, 이거랑 아주 달라 보이죠.
74
00:04:35,309 --> 00:04:38,964
당연히 우리는 어떻게든 정밀하게 이것을 이걸로 변환할 방법이 있어야겠죠.
75
00:04:38,964 --> 00:04:44,683
좋은 소식은, 샘플링 이론이 우리가 어떻게 하면 되는지 알려준다는 것입니다.
76
00:04:44,683 --> 00:04:48,477
클로드 섀넌에 의해 1949년에 가장 유명한 형태로 출판되었고
77
00:04:48,477 --> 00:04:52,409
나이퀴스트, 하틀리와 수많은 다른 사람들의 업적에 기반하는
78
00:04:52,409 --> 00:04:56,138
샘플링 이론은 단순히 우리가 아날로그와 디지털 사이를 오갈 수 있음을 말하는 데 그치지 않고
79
00:04:56,138 --> 00:05:00,913
어떤 조건 하에서 손실없이 변환을 할 수 있는지
80
00:05:00,913 --> 00:05:06,779
또 디지털과 아날로그 두 표현이 동일하고 서로 바뀔 수 있는지 알려줍니다.
81
00:05:06,779 --> 00:05:10,601
무손실 조건이 만족되지 않으면, 샘플링 이론은 어떻게, 그리고 얼마나
82
00:05:10,601 --> 00:05:14,247
정보가 손실되거나 오염되는지 알려줍니다.
83
00:05:14,900 --> 00:05:21,270
아주 최근까지도, 아날로그 기술은 실질적으로 오디오의 기본이었는데,
84
00:05:21,270 --> 00:05:25,267
그건 대부분의 오디오가 근본적으로 아날로그 원천에서 나와서가 아닙니다.
85
00:05:25,267 --> 00:05:28,450
그리고 당신은 컴퓨터들은 상당히 최근에 만들어졌으니
00:05:28,450 --> 00:05:31,643
아날로그 신호 기술이 먼저 나왔을 것이라 생각할 수 있습니다.
87
00:05:31,643 --> 00:05:34,428
아닙니다. 다지털이 사실 먼저입니다.
88
00:05:34,428 --> 00:05:37,611
전신이 전화보다 반세기는 빨리 나왔고
89
00:05:37,611 --> 00:05:41,951
이미 전신은 1806년대에 완전히 기계적으로 자동화되었고, 디지털 코드를 전송했고
90
00:05:41,951 --> 00:05:46,476
디지털 신호들을 다중화하여 먼 곳으로 전송했습니다. 종이 테이프 아시죠?
91
00:05:46,476 --> 00:05:50,427
벨 연구소의 해리 나이퀴스트는 전신의 펄스 전송을 연구하고 있었는데
92
00:05:50,427 --> 00:05:53,027
그 때 샘플링 이론의 핵심 개념이 된, 나이퀴스트 주파수라는
93
00:05:53,027 --> 00:05:57,219
개념을 발표하였습니다.
94
00:05:57,219 --> 00:06:01,642
전신은 기호화된 정보, 문자들을 보낸 것이지 디지털화된 아날로그 신호를 보낸 것은 아닙니다만,
95
00:06:01,642 --> 00:06:06,883
전화와 라디오의 발전에 의해 아날로그와 디지털 신호 기술은
96
00:06:06,883 --> 00:06:12,000
모두 같이 발전했습니다.
97
00:06:12,699 --> 00:06:18,732
오디오는 늘 아날로그 신호로서 조작되었는데, 그 이유는 그게 훨씬 쉽기 때문이었죠.
98
00:06:18,732 --> 00:06:23,257
예를 들어 2차 저대역 통과 필터는 두 개의 수동 소자로만 이루어집니다.
99
00:06:23,257 --> 00:06:26,505
완전-아날로그 단시간 푸리에 변환은 수백 개 정도이구요.
100
00:06:26,505 --> 00:06:30,752
글쎄요, 당신이 정말 멋진 뭔가를 만들고자 하면 수천 개가 필요할 겁니다.
101
00:06:31,844 --> 00:06:35,989
디지털로 신호 처리를 하려면 수백 MHz에서 GHz 속도로 작동하는
102
00:06:35,989 --> 00:06:40,366
수백만에서 수십억 개의 트랜지스터들이 필요하고, 최소한 디지털-아날로그 변환을 해주는 하드웨어와
103
00:06:40,366 --> 00:06:43,836
그 수십억의 엄청난 트랜지스터들을 프로그래밍하고 조정할 수 있는
104
00:06:43,836 --> 00:06:47,362
완전한 소프트웨어 생태계가 필요하고,
105
00:06:47,362 --> 00:06:51,091
만약 그 비트들을 저장하고자 한다면 디지털 저장장치가 필요합니다.
106
00:06:51,091 --> 00:06:56,171
따라서 아날로그가 현실적으로 오디오를 다룰 수 있는 방법이라는 결론이 나오지요.
107
00:06:56,171 --> 00:07:07,019
수십억 개의 트랜지스터들과 다른 것들이 없다면요.
108
00:07:07,850 --> 00:07:12,660
그리고 우리는 그것들을 갖고 있으니, 디지털 신호 처리가 아주 매력적이 되었습니다.
109
00:07:13,363 --> 00:07:18,906
한 예로, 아날로그 구성 요소는 범용 컴퓨터가 갖고 있는 유연성이 없습니다.
110
00:07:18,906 --> 00:07:21,182
이 괴물에 새로운 기능을 추가한다든가요...
111
00:07:22,191 --> 00:07:24,578
그래요, 아마 불가능할 겁니다.
112
00:07:24,578 --> 00:07:26,567
하지만 디지털 프로세서라면...
113
00:07:28,668 --> 00:07:34,127
그저 새 프로그램을 작성하면 됩니다. 소프트웨어는 시시하진 않지만, 훨씬 쉽습니다.
114
00:07:34,127 --> 00:07:39,550
어쩌면, 더 중요한 것은 모든 아날로그 구성요소들은 그저 근사적으로 작동할 뿐이라는 것이죠.
115
00:07:39,550 --> 00:07:44,352
완벽한 트랜지스터나 완벽한 인덕터, 완벽한 커패시터란 것은 없습니다.
116
00:07:44,352 --> 00:07:51,569
아날로그에서는, 모든 구성요소가 잡음과 왜곡을 더합니다. 보통은 심하지 않지만, 그것들이 다 더해지죠.
117
00:07:51,569 --> 00:07:55,669
그저 아날로그 신호를 보내기만 해도, 특히 먼 거리일수록,
118
00:07:55,669 --> 00:08:00,434
점점 더, 측정할 수 있을 만큼, 돌이킬 수 없게 손상됩니다.
119
00:08:00,434 --> 00:08:06,513
게다가, 각각 하나의 목적만을 위한 아날로그 구성 요소들은 많은 공간을 차지합니다.
120
00:08:06,513 --> 00:08:09,946
여기 수십억 트랜지스터들에 대한 두 줄의 코드로
121
00:08:09,946 --> 00:08:14,702
냉장고만한 인덕터가 필요한 필터를 구현할 수 있습니다.
122
00:08:14,702 --> 00:08:17,941
디지털 시스템은 그런 단점이 없지요.
123
00:08:17,941 --> 00:08:24,335
디지털 신호는 추가적인 잡음이나 왜곡 없이 저장, 복사, 조작, 전송이 가능합니다.
124
00:08:24,335 --> 00:08:26,889
우리는 손실이 발생하는 알고리즘을 때때로 쓰지만,
125
00:08:26,889 --> 00:08:31,284
불가피한 비이상적인 과정은 디지털화와 아날로그로의 재구성으로,
126
00:08:31,284 --> 00:08:35,929
디지털이 그 온갖 지저분한 아날로그와 만나야 하는 지점입니다.
127
00:08:35,929 --> 00:08:40,750
지저분하건 아니건, 현대적인 변환 과정은 아주, 아주 훌륭합니다.
128
00:08:40,750 --> 00:08:45,849
우리 귀에 대해 일반적으로, 우리는 그 과정이 역시 실질적으로 무손실이라고 생각할 수 있습니다.
129
00:08:45,849 --> 00:08:50,429
현대의 산업 기반에 의해 대부분 작고 저렴하게 만들어질 수 있는 조금의 하드웨어가 있다면
130
00:08:50,429 --> 00:08:55,379
디지털 오디오는 아날로그에 대한 완벽한 승자입니다.
131
00:08:55,379 --> 00:09:00,857
그럼 디지털 신호를 저장하고, 복사하고, 다루고, 전송하는 것을 알아보죠.
132
00:09:04,956 --> 00:09:08,639
펄스 부호 변조는 원본 오디오에 대한 가장 일반적인 표현입니다.
133
00:09:08,639 --> 00:09:13,867
다른 실제로 쓰이는 방법들도 있습니다. 예를 들면 SACD에서 쓰이는 시그마-델타 코딩이 있는데,
134
00:09:13,867 --> 00:09:16,625
이는 펄스 밀도 변조의 한 종류입니다.
135
00:09:16,625 --> 00:09:19,687
어쨌건, 펄스 코드 변조는 가장 일반적인데,
136
00:09:19,687 --> 00:09:22,158
그 이유는 이게 가장 수학적으로 편리해서입니다.
137
00:09:22,158 --> 00:09:26,350
오디오 엔지니어는 다른 걸 할 필요 없이 PCM만 할지도 몰라요.
138
00:09:26,350 --> 00:09:29,135
PCM 부호화는 세 가지 매개변수로 그 특성이 결정되는데,
139
00:09:29,135 --> 00:09:34,187
이로부터 자비롭게 적은 노력으로 모든 PCM 종류들을 다룰 수 있게 됩니다.
140
00:09:34,187 --> 00:09:36,426
첫 번째 매개변수는 샘플링 속도입니다.
141
00:09:36,426 --> 00:09:40,886
한 부호화가 표현할 수 있는 가장 높은 주파수를 나이퀴스트 주파수라고 부릅니다.
142
00:09:40,886 --> 00:09:45,124
PCM의 나이퀴스트 주파수는 정확히 샘플링 속도의 절반입니다.
143
00:09:45,124 --> 00:09:51,389
따라서, 샘플링 속도는 직접적으로 디지털화되는 신호의 가능한 최고 주파수를 결정하게 됩니다.
144
00:09:51,389 --> 00:09:56,515
아날로그 전화 시스템은 전통적으로 4 KHz 이하로 대역제한되는 음성 채널을 사용했는데,
145
00:09:56,515 --> 00:10:02,224
따라서 디지털 전화와 대부분의 고전적인 음성 응용 시스템은 8 KHz의 샘플링 속도를 사용합니다.
146
00:10:02,224 --> 00:10:07,277
이 속도는 4 KHz 채널의 전체 대역폭을 획득하기 위한 최소 샘플링 속도입니다.
147
00:10:07,227 --> 00:10:14,263
이것이 8 KHz 샘플링 속도로 샘플링한 음성의 소리입니다---조금 웅얼거리지만 음성을 완전히 알아들을 수는 있죠.
148
00:10:17,263 --> 00:10:18,149
이것이 실질적으로 널리 쓰여온 가장 낮은 샘플링 속도입니다.
149
00:10:18,149 --> 00:10:23,322
일반 사용자용 컴퓨터 하드웨어의 성능, 메모리, 저장장치가 증가하면서,
150
00:10:23,322 --> 00:10:29,642
여기서부터 시작하여 11, 다음엔 16, 다음엔 22, 그 다음엔 32 kHz 샘플링이 지원되기 시작했습니다.
151
00:10:29,642 --> 00:10:33,491
With each increase in the sampling rate and the Nyquist frequency, 
샘플링 속도와 그에 따른 나이퀴스트 주파수가 증가함에 따라,
152
00:10:33,491 --> 00:10:38,302
분명히 고주파 부분이 좀 더 선명해지고, 소리가 더 자연스러워졌습니다.
153
00:10:38,301 --> 00:10:44,576
CD는 44.1 kHz의 샘플링 속도를 사용하는데, 이는 32 kHz보다도 약간 더 좋지만
154
00:10:44,576 --> 00:10:46,788
그에 따른 이점은 덜 분명해집니다.
155
00:10:46,788 --> 00:10:52,053
44.1 kHz는 특이한 선택으로, 이 속도는 CD 이전엔 사용된 적이 없습니다.
156
00:10:52,053 --> 00:10:56,559
하지만 CD의 엄청난 성공에 따라 이 속도가 일반적인 샘플링 속도가 되었습니다.
157
00:10:56,559 --> 00:11:01,195
CD 이외의 가장 일반적인 고음질을 위한 샘플링 속도는 48 kHz입니다.
158
00:11:05,710 --> 00:11:08,597
현실적으로 그 둘 사이에서 들을 수 있는 차이는 없습니다.
159
00:11:08,597 --> 00:11:13,640
이 비디오나, 아니면 이 비디오의 원래 버전은 48 kHz의 오디오로 촬영되고 제작되었는데,
160
00:11:13,640 --> 00:11:18,545
이는 동영상의 고음질 오디오의 원래 표준입니다.
161
00:11:18,545 --> 00:11:25,100
88, 96, 그리고 192 kHz의 초고음질 샘플링 속도도 등장했습니다.
162
00:11:25,100 --> 00:11:30,888
48 kHz를 넘어서는 샘플링 속도를 사용하는 이유는 들을 수 있는 주파수 범위를 더 넓히는 게 아닙니다.
163
00:11:30,888 --> 00:11:32,489
다른 이유가 있어서에요.
164
00:11:32,896 --> 00:11:37,319
조금 뒤로 돌아가서, 장 밥티스트 조셉 푸리에라는 프랑스 수학자는
165
00:11:37,319 --> 00:11:42,353
오디오와 같은 신호는 그것을 구성하는 주파수 성분들의 모음이라고 생각할 수 있음을 보였지요.
166
00:11:42,353 --> 00:11:45,841
이 주파수 영역의 표현은 시간 영역 표현과 동등합니다.
167
00:11:45,841 --> 00:11:49,719
신호는 똑같지만, 다른 방식으로 볼 뿐이지요.
168
00:11:49,719 --> 00:11:56,131
여기 우리가 디지털로 샘플링하고자 하는 가상의 아날로그 신호에 대한 주파수 영역 표현이 있습니다.
169
00:11:56,131 --> 00:11:59,888
샘플링 이론은 샘플링 과정에 대해 두 가지 중요한 것을 얘기합니다.
170
00:11:59,888 --> 00:12:04,727
첫째, 디지털 신호는 나이퀴스트 주파수를 넘어서는 어떠한 주파수도 표현할 수 없습니다.
171
00:12:04,727 --> 00:12:10,640
둘쨰, 이건 새로운 내용인데, 우리가 그 주파수들을 저대역 통과 필터로 샘플링 전에 없애지 않는다면
172
00:12:10,640 --> 00:12:16,414
샘플링 과정은 그 주파수들을 표현될 수 있는 주파수 범위로 낮춰서 에일리어싱 왜곡이라는 것이 나타나게 할 겁니다.
173
00:12:16,414 --> 00:12:20,069
요약하자면 에일리어싱은 끔찍하게 이상하게 들리는 소리라서
174
00:12:20,069 --> 00:12:25,242
반드시 나이퀴스트 주파수를 넘어서는 주파수들을 샘플링 전과 아날로그 재구성 후에 제거해야 합니다.
175
00:12:25,871 --> 00:12:31,265
인간의 주파수 감지 범위는 20 kHz 범위까지인 것으로 생각됩니다.
176
00:12:31,265 --> 00:12:37,548
44.1 kHz나 48 kHz 샘플링에서, 샘플링 전의 저대역 통과 필터는 아주 날카로워야 하는데
177
00:12:37,548 --> 00:12:42,101
이는 20 kHz 미만의 들을 수 있는 주파수가 잘리는 것을 막고
178
00:12:42,101 --> 00:12:49,439
나이퀴스트 주파수를 넘어서는 주파수가 샘플링 과정으로 들어가는 것을 막아야 하기 떄문입니다.
179
00:12:49,439 --> 00:12:55,342
이는 만들기 어렵고 현실적으로 어떤 필터도 완전히 성공할 수 없는 목표입니다.
180
00:12:55,342 --> 00:13:00,024
하지만 만약 샘플링 주파수가 96 kHz 또는 192 kHz라면
181
00:13:00,024 --> 00:13:07,223
저대역 필터의 통과-제한 대역에 1~2옥타브의 여유가 생깁니다(주: 덜 날카로워도 됩니다.) 따라서 훨씬 만들기 쉬운 필터가 됩니다.
182
00:13:07,223 --> 00:13:14,348
48 kHz를 넘어서는 샘플링 속도는 사실 이러한 지저분한 아날로그 단과 타협하기 위함입니다.
183
00:13:15,014 --> 00:13:20,844
두 번째의 근본적은 PCM 매개변수는 샘플링 형식으로, 각 디지털 숫자에 대한 형식입니다.
184
00:13:20,844 --> 00:13:26,285
하나의 숫자는 하나의 숫자이지만, 그 하나의 숫자는 아주 다양한 방법으로 비트들로 표현됩니다.
185
00:13:26,942 --> 00:13:30,902
초기의 PCM은 선형적으로 8개의 비트를 이용하여 부호 없는 1바이트로 부호화하였습니다.
186
00:13:30,902 --> 00:13:37,028
이에 따라 다이내믹 레인지는 약 50 dB로 제한되었으며(주: 20(log 2^8)/log 10 = 48), 들으시는 것처럼 상당히 열악합니다.
187
00:13:37,028 --> 00:13:39,970
8 비트 오디오는 거의 사라져서 오늘날엔 드뭅니다.
188
00:13:41,007 --> 00:13:47,484
디지털 전화는 보통 서로 상관있는 비선형 8비트 부호화인 A-법칙과 mu-법칙이라는
두 방법 중 하나를 사용합니다.
189
00:13:47,484 --> 00:13:51,287
이 형식들은 대략 14 비트의 다이내믹 레인지를 8 비트로 변환하는데 그 방법은
190
00:13:51,287 --> 00:13:54,674
높은 진폭값에 대한 양자화 간격을 훨씬 멀리 떨어뜨리는 것입니다.
191
00:13:54,674 --> 00:13:59,226
A-법칙과 mu-법칙은 선형 8비트 대비 분명한 양자화 잡음 감소를 보여주며
192
00:13:59,226 --> 00:14:03,557
음성 배음들은 특히나 남아있는 양자화 잡음을 잘 숨겨줍니다.
193
00:14:03,557 --> 00:14:08,248
이 세 가지 8비트 부호화, 즉 선형, A-법칙, mu-법칙은 보통 8 kHz 샘플링 속도와 같이 쓰입니다.
194
00:14:08,248 --> 00:14:13,328
비록 전 지금 48 kHz에 대해 얘기하고 있지만요.
195
00:14:13,328 --> 00:14:18,491
대부분의 현대 PCM은 16 또는 24비트의 2의 보수로 표현되는 부호 있는 정수를 이용합니다.
196
00:14:18,491 --> 00:14:23,858
음의 무한대부터 0 dB까지의 범위가 16 또는 24 비트의 정밀도로 표현됩니다.
197
00:14:23,858 --> 00:14:27,800
최대 절댓값은 0 dB에 해당합니다.
198
00:14:27,800 --> 00:14:31,584
지금까지의 다른 모든 샘플 형식들과 마찬가지로, 0 dB를 넘는 신호들
199
00:14:31,584 --> 00:14:35,619
즉 최대 표현 범위를 벗어나는 신호들은 최댓값으로 고정(클리핑)됩니다.
200
00:14:35,619 --> 00:14:41,199
믹싱과 마스터링에서 PCM 값들을 정수가 아닌 부동 소수점으로 표현하는 것은 드물지 않습니다.
201
00:14:41,199 --> 00:14:47,222
현재의 컴퓨터에서 일반적으로 볼 수 있는 IEEE754 32 비트 부동 소수점 표현 방식은
202
00:14:47,222 --> 00:14:52,793
24 비트의 해상도를 갖습니다만, 7 비트의 부동 소수점 지수부는 표현 범위를 더 넓힙니다.
203
00:14:52,793 --> 00:14:57,040
부동 소수점은 보통 0 dB를 +/-1.0으로 표현하고
204
00:14:57,040 --> 00:15:00,547
또 부동 소수점은 확실히 그보다 훨씬 큰 값들을 표현할 수 있기 때문에
205
00:15:00,547 --> 00:15:05,220
믹싱 과정에서 일시적으로 0 dB를 넘는 값은 클리핑을 일으키지 않습니다.
206
00:15:05,220 --> 00:15:11,077 
부동 소수점 PCM은 더 많은 메모리와 저장 공간을 요구하기에, 보통 중간 제작 형식으로만 사용됩니다.
207
00:15:11,077 --> 00:15:15,796
그리고, 대부분의 범용 컴퓨터들이 데이터를 8 바이트 단위로 읽고 쓰기 때문에
208
00:15:15,796 --> 00:15:18,489
8 비트를 넘는 샘플들은 빅 엔디안 또는 리틀 엔디안 형식이 될 수 있으며
209
00:15:18,489 --> 00:15:22,838
두 엔디안 모두 일반적임을 기억하는 게 중요합니다.
210
00:15:22,838 --> 00:15:28,751
예를 들어, 마이크로소프트 WAV 파일들은 리틀 엔디안을 사용하고, 애플 AIFC 파일들은 빅 엔디안을 사용합니다.
211
00:15:28,751 --> 00:15:30,139
명심하세요.
212
00:15:30,870 --> 00:15:34,071
세 번째 PCM 매개변수는 채널 수입니다.
213
00:15:34,071 --> 00:15:38,485
본래의 PCM의 관습은 여러 채널들에 대해서 샘플들을 인터리브하여(서로서로 끼워넣어서)
214
00:15:38,485 --> 00:15:43,398
하나의 단일 스트림으로 만드는 것입니다. 직관적이고 확장 가능하지요.
215
00:15:43,398 --> 00:15:47,701
바로 그겁니다! 이게 모든 PCM 표현들을 설명합니다.
216
00:15:47,701 --> 00:15:51,578
끝입니다. 디지털 오디오 참 쉽죠!
217
00:15:51,578 --> 00:15:56,436
물론 더 많은 것들이 있지만, 지금 단계에서 우리는 오디오 데이터에 대해 훌륭하고 유용한 부분을 얻었습니다.
218
00:15:56,436 --> 00:15:58,092
그러니 이제 비디오에 대해서도 얻어보죠
219
00:16:02,571 --> 00:16:08,798
누군가는 비디오가 시간에다가 두 개의 추가적인 공간 차원, X와 Y가 있는 오디오와 비슷하다고 생각할 수도 있어요.
220
00:16:08,798 --> 00:16:12,787
이는 수학적으로 타당합니다.
221
00:16:12,787 --> 00:16:19,097
샘플링 이론은 하나의 차원만 있는 오디오에 적용되는 것처럼 세 비디오 차원들에 대해서도 적용됩니다.
222
00:16:19,097 --> 00:16:25,815
오디오와 비디오는 분명히 실질적으로는 다릅니다. 예를 들어, 오디오에 비해 비디오는 훨씬 큽니다.
223
00:16:25,815 --> 00:16:29,294
본래 CD 오디오는 약 1.4 Mbps의 전송률을 갖습니다.
224
00:16:29,294 --> 00:16:33,958
본래 1080i HD 비디오는 700 Mbps를 넘죠.
225
00:16:33,958 --> 00:16:40,056
이는 초당 500배 이상의 데이터를 잡아내서 처리하고 저장하는 것에 해당합니다.
226
00:16:40,056 --> 00:16:43,711
무어의 법칙에 따르면, 음..., 2년마다 두 배로 약 8번을 해야하니까... 
227
00:16:43,711 --> 00:16:47,838
네, 약 15년 정도 더 컴퓨터가 발전해야
228
00:16:47,838 --> 00:16:51,252
오디오처럼 본래 비디오를 처리할 수 있겠네요.
229
00:16:51,252 --> 00:16:55,425
기본적인 본래 비디오는 본래 오디오보다 더 복잡하기도 합니다.
230
00:16:55,425 --> 00:16:58,599
현재 비디오 데이터 크기는 오디오에서 쓰이는
231
00:16:58,599 --> 00:17:02,106 
선형 PCM보다 더 효율적인 표현을 요구합니다.
232
00:17:02,106 --> 00:17:06,705
게다가, 전자적인 비디오는 거의 전적으로 방송 TV를 통해서 전달되므로
233
00:17:06,705 --> 00:17:13,423
방송 비디오를 다루는 표준화 기구는 하위 호환성을 늘 신경써 왔습니다.
234
00:17:13,423 --> 00:17:17,559  
미국에선 작년까지도 60년 전의 흑백 TV로
235
00:17:17,559 --> 00:17:21,038
일반 아날로그 방송을 시청할 수 있었습니다.
236
00:17:21,038 --> 00:17:23,879
굉장히 멋집니다.
237
00:17:23,879 --> 00:17:28,718
하위 호환성의 안좋은 면은 한번 세부 사항이 표준으로 정해지면
238
00:17:28,718 -->  00:17:30,985
그걸 다시 없애버릴 수 없다는 거죠.
239
00:17:30,985 --> 00:17:37,305
전자적 비디오는 오디오가 여러 번 겪었던 처음부터 창조되는 과정을 겪지 않았습니다.
240
00:17:37,305 --> 00:17:43,958
60년 동안 쌓인 당시 기술에서 요구된 영리하지만 구식인 방법들은
241
00:17:43,958 --> 00:17:50,102
커다란 더미가 되었고, 디지털 표준들 또한 방송 TV에 근본이 있기 때문에
242
00:17:50,102 --> 00:17:54,664
이 모든 무시무시한 방법들은 디지털 표준에도 들어왔습니다.
243
00:17:54,664 --> 00:18:00,022
즉, 디지털 비디오와 관련된 세부 사항들은 오디오에 비해 훨씬 많다는 것입니다.
244
00:18:00,022 --> 00:18:05,592
그것들을 여기서 전부 다룰 수는 없으니, 우리는 널리 쓰이는 기본적인 것을 다루겠습니다.
245
00:18:06,036 --> 00:18:10,857
명확한 본래 비디오의 매개변수는 픽셀로 표현된 비디오의 폭과 높이입니다.
246
00:18:10,857 --> 00:18:15,882
들리는 것처럼, 픽셀 차원만으로는 그림의 실제 폭과 높이를 표현하지 못합니다.
247
00:18:15,882 --> 00:18:22,016
대부분의 방송에서 기인한 비디오는 정사각형 픽셀을 쓰지 않기 때문이죠.
248
00:18:22,016 --> 00:18:25,005
방송 영상의 주사선 수는 고정이지만
249
00:18:25,005 --> 00:18:29,021
실질적인 수평 픽셀 개수는 채널 대역폭과 상관있습니다.
250
00:18:29,021 --> 00:18:31,945
실질 수평 해상도는 주사선 간의 간격보다 좁거나 넓은
251
00:18:31,945 --> 00:18:35,489
픽셀들을 만들 수 있습니다.
252
00:18:35,489 --> 00:18:38,395
표준들은 일반적으로 디지털로 샘플링된 비디오들이
253
00:18:38,395 --> 00:18:41,902
원본 아날로그 소스의 해상도를 반영하도록 정해집니다.
254
00:18:41,902 --> 00:18:45,566
따라서 많은 비디오들이 정사각형이 아닌 픽셀을 사용합니다.
255
00:18:45,566 --> 00:18:49,924
예를 들어, 일반적인 4:3 비율의 NTSC DVD는
256
00:18:49,924 --> 00:18:55,374
보통 704 x 480의, 4:3보다 넓은 화면 해상도로 부호화됩니다.
257
00:18:55,374 --> 00:18:59,640
이러한 경우, 픽셀 자체의 해상도는 10:11이 되는데,
258
00:18:59,640 --> 00:19:04,553
따라서 픽셀들은 너비보다 높이가 커지고, 이미지가 정확한 종횡비보다
수평 방향으로 좁게 됩니다.
259
00:19:04,553 --> 00:19:09,800
그러한 이미지들은 정사각형의 픽셀을 갖는 디지털 디스플레이에서 제대로 보이게 다시 샘플링되어야 합니다.
260
00:19:10,253 -->  00:19:15,287
두 번째로 분명한 비디오 매개변수는 프레임율로, 초당 프레임 수를 말합니다.
261
00:19:15,287 --> 00:19:19,655
몇몇 표준 프레임율은 실제로 사용되고 있습니다. 특정 형식이나 그와 다른 형식의 디지털 비디오는,
262
00:19:19,655 --> 00:19:23,689
그 모든 프레임율이나 또 다른 프레임율을 쓸 수 있습니다. 또는 비디오가 진행됨에 따라
263
00:19:23,689 --> 00:19:27,113
적응적으로 달라지는 가변 프레임율을 쓸 수도 있지요.
264
00:19:27,113 --> 00:19:32,998
프레임율이 높을수록 움직임은 부드럽게 보이고, 이는 불행히도 인터레이싱(비월주사)을 도입하게 합니다.
265
00:19:32,998 --> 00:19:37,967
방송 비디오의 초창기에, 엔지니어들은 형광 물질을 사용하는 CRT 모니터에서 플리커(깜빡임)을 최소화하고
266
00:19:37,967 --> 00:19:42,075
움직임을 부드럽게 만드는 현실적으로 가장 빠른 프레임율을 찾았습니다.
267
00:19:42,075 --> 00:19:45,277
그들은 또 최고의 해상도와 프레임율에 대한
268
00:19:45,277 --> 00:19:48,182
최소의 대역폭을 사용해야 한다는 압박을 받았지요.
269
00:19:48,182 --> 00:19:51,208
그들이 찾은 방법은 짝수 번째 선들을 한번 보내고 홀수 선들을 그 다음에 보내는
270
00:19:51,208 --> 00:19:54,826
인터레이싱이라는 방법이었습니다.
271
00:19:54,826 --> 00:19:59,961
각 전송 순서는 필드라고 부르고, 두 필드가 하나의 완전한 프레임 같은 것을 만듭니다.
272
00:19:59,961 --> 00:20:05,319
"같은 것"이란 표현을 쓴 이유는 짝수와 홀수 필드가 사실상 같은 근원 프레임에서 오는 것이 아니기 때문입니다.
273
00:20:05,319 --> 00:20:10,797
초당 60 필드의 그림에서, 근원 프레임율은 실제로 완전한 초당 60 프레임이지만,
274
00:20:10,797 --> 00:20:15,386
홀수 또는 짝수 번째 선들로 이루어지는 각 프레임의 절반만 취해지고 나머지 절반은 버려집니다.
275
00:20:15,386 --> 00:20:20,272
이것이 우리가 비디오의 각 필드를 한 프레임으로 합쳐도 디인터레이싱이 되지 않는 이유입니다.
276
00:20:20,272 --> 00:20:23,039
필드들은 하나의 프레임에서 만들어진 게 아니니까요.
277
00:20:24,047 --> 00:20:29,683
CRT는 대부분의 전자 비디오 역사에서 유일하게 가능한 디스플레이 기술이었습니다.
278
00:20:29,683 --> 00:20:32,949
CRT의 출력 밝기는 비선형적인데,
279
00:20:32,949 --> 00:20:36,585
대략 입력되는 조절 전압의 2.5승과 같습니다.
280
00:20:36,585 --> 00:20:43,821
이 2.5라는 지수승은 감마라고 정해지며, 따라서 보통 디스플레이 감마라고 불립니다.
281
00:20:43,821 --> 00:20:50,493
하지만 카메라들은 선형적이어서, CRT에 선형 신호를 입력하면 
이런 식으로 보이게 됩니다.
282
00:20:51,270 --> 00:20:56,637
당시에는, 어마어마하게 비쌌던, 카메라들은 비교적 소수 존재했고
283
00:20:56,637 --> 00:21:01,634
최대한 저렴해야 하는 TV들은 많았기 때문에
284
00:21:01,634 --> 00:21:08,222
엔지니어들은 감마 보정 회로를 TV가 아닌 카메라에 넣기로 결정했습니다.
285
00:21:08,222 --> 00:21:13,062
따라서 공중파를 통해 전달된 비디오들은 비선형적인 세기를 갖게 되었는데
286
00:21:13,062 --> 00:21:18,271
그 함수는 TV 수상기 감마 지수함수의 역함수이고, 따라서 카메라의 신호가 CRT에서 표시될 때엔
287
00:21:18,271 --> 00:21:23,305
카메라에서 TV로 전달된 전체적인 응답은 다시 선형적으로 됩니다.
288
00:21:23,777 --> 00:21:25,118
거의요.
289
00:21:30,393 --> 00:21:33,113
두 가지 개선사항이 더 있습니다.
290
00:21:33,113 --> 00:21:40,442
TV 카메라는 사실 2.5가 아닌 2.2 감마 지수의 역수를 씁니다.
291
00:21:40,442 --> 00:21:43,754
이는 어두운 환경에서 볼 때에 대한 보정입니다.
292
00:21:43,754 --> 00:21:48,279
또한, 지수 곡선은 검정 부근에서 직선으로 바뀝니다.
293
00:21:48,279 --> 00:21:52,360
이는 카메라의 센서 잡음을 줄이기 위한 오래된 방법입니다.
294
00:21:54,941 --> 00:21:57,347
또 감마 보정은 운 좋게도 추가적인 이득을 줍니다.
295
00:21:57,347 --> 00:22:02,214
인간의 눈은 3이란 감마 값을 갖는 인지적 특성을 보입니다.
296
00:22:02,214 --> 00:22:05,962
이는 상대적으로 CRT의 감마인 2.5에 가깝죠.
297
00:22:05,962 --> 00:22:10,607
감마 보정을 하는 영상은 낮은 세기의 값을 더 잘 표현하게 되는데
298
00:22:10,607 --> 00:22:14,336
눈의 세기 분해능은 이 범위에서 가장 좋습니다.
299
00:22:14,336 --> 00:22:18,222
따라서 사용 가능한 값의 해상도를 더 효율적으로 사용할 수 있게 되는 것입니다.
300
00:22:18,222 --> 00:22:22,784
비록 CRT들은 사라지고 있지만, 표준 sRGB 컴퓨터 화면들은
301
00:22:22,784 --> 00:22:28,419
TV와 비슷하게, 검정 근처에선 직선이며, 2.4의 감마 지수승을 갖는 지수함수 형태의
302
00:22:28,419 --> 00:22:32,491
비선형적인 세기 곡선을 사용합니다.
303
00:22:32,491 --> 00:22:36,636
이것은 16 비트의 선형 범위를 8 비트로 변환합니다.
304 
00:22:37,580 --> 00:22:41,790
인간의 눈은 빨강, 초록, 파랑의 3개의 색 채널을 갖고 있고
305
00:22:41,790 --> 00:22:47,407
대부분의 디스플레이들은 이 세 색깔을 합성의 근본 원소로 사용하여 전체 출력 색상을 만듭니다.
306
00:22:49,258 --> 00:22:54,190
인쇄에서 사용되는 색소의 삼원색이 사이안, 마젠타, 노랑인 것과 같은 이유입니다.
307
00:22:54,190 --> 00:22:59,381
색소들에는 뺄셈이 적용되며, 각 색소들은 반새된 빛에서 하나의 순수한 색을 뺸 것입니다.
308
00:22:59,381 --> 00:23:05,682
사이안은 빨강, 마젠타는 초록, 노랑은 파랑을 뺍니다.
309
00:23:05,682 --> 00:23:10,919
비디오는 빨강, 초록, 파랑 채널들로 표현될 수 있고(RGB), 실제로 가끔 그렇게 표현되지만,
310
00:23:10,919 --> 00:23:17,211
RGB 비디오는 일반적이지 않습니다. 인간의 눈은 색보다는 밝기에 훨씬 민감한데,
311
00:23:17,211 --> 00:23:21,329
RGB는 영상의 이미지를 세 채널에 분산시킵니다.
312
00:23:21,329 --> 00:23:25,326
이는, 빨강 평면은 원래 그림의 빨간 버전으로 보이고
313
00:23:25,326 --> 00:23:28,769
초록 평면은 원래 그림의 초록 버전으로 보이고
314
00:23:28,769 --> 00:23:32,063
파랑 평면은 원래 그림의 파랑 버전으로 보일 것입니다.
315
00:23:32,063 --> 00:23:35,705
흑백이 세 번 필요한 것이죠. 효율적이지 않습니다.
316
00:23:35,706 --> 00:23:39,438
이런 이유로, 또 그리고 TV는 어쨌건 흑백에서 시작됐기 때문에
317
00:23:39,438 --> 00:23:45,017
비디오는 보통 높은 해상도의 밝기 채널, 즉 흑백 채널과
318
00:23:45,017 --> 00:23:51,041
보통 더 낮은 해상도를 갖는 색상 채널들로 표현됩니다.
319
00:23:51,041 --> 00:23:57,074
밝기 채널, Y는 개별 빨강, 초록, 파랑 신호에 가중치를 곱해서 더함으로써 만들어집니다.
320
00:23:57,074 --> 00:24:01,867
색상 채널들 U와 V는 밝기 채널에서 각각 파랑과
321
00:24:01,867 --> 00:24:04,070
빨강을 뺌으로써 만들어집니다.
322
00:24:04,070 --> 00:24:11,750
YUV가 측정되고, 오프셋이 더해지고 양자화되오 디지털 비디오가 되면, 보통 더 정확히는 Y'CbCr이라고 불려야 하지만
323
00:24:11,750 --> 00:24:15,238
YUV라는 더 일반적인 용어가 이 색상 모델을 설명할 때
324
00:24:15,238 --> 00:24:18,301
아날로그와 디지털 모두에서 사용됩니다.
325
00:24:18,912 --> 00:24:22,983
U와 V 색상 채널은 Y 채널과 같은 해상도를 가질 수 있지만,
326
00:24:22,983 --> 00:24:28,674
인간의 눈은 밝기에 대한 공간 해상도보다 색상에 대한 공간 해상도가 훨씬 낮기 때문에
327
00:24:28,674 --> 00:24:34,346
색상 해상도는 수평 방향 또는 수직 방향으로, 혹은 두 방향 모두에서 밝기 해상도의 절반이나 1/4를 갖습니다.
328
00:24:34,346 --> 00:24:39,528
그렇게 해도 원본 이미지 대비 큰 영향은 없습니다.
329
00:24:39,528 --> 00:24:43,942
실질적으로 모든 서브샘플링 변형들이 사용되곤 했지만,
330
00:24:43,942 --> 00:24:46,875
오늘날 일반적인 선택은
331
00:24:46,875 --> 00:24:51,187
서브샘플링되지 않은 4:4:4 비디오,
332
00:24:51,187 --> 00:24:56,711
U와 V 방향 수평 해상도가 절반인 4:2:2 비디오,
333
00:24:56,711 --> 00:25:02,587
그리고 가장 일반적인 색상 해상도의 수평, 수직 해상도가 절반인 4:2:0 비디오가 있는데
334
00:25:02,587 --> 00:25:08,897
따라서 이 경우 각각의 U와 V 평면의 크기는 Y의 1/4가 됩니다.
335
00:25:08,897 --> 00:25:17,096
4:2:2, 4:2:0, 4:1:1과 다른 것들은 색상 서브샘플링의 완전한 설명들이 아닙니다.
336
00:25:17,096 --> 00:25:21,186
밝기에 대해서 색상 픽샐들을 배치하는 여러 방법들이 있고,
337
00:25:21,096 --> 00:25:24,776 
다시 여러 변형들이 각 서브샘플링에 이용됩니다.
338
00:25:24,776 --> 00:25:32,502
예를 들어, 모션 JPEG, MPEG-1 비디오, MPEG-2 비디오, DV, Theora와 WebM 모두
339
00:25:32,502 --> 00:25:38,137
4:2:0 서브샘플링을 이용하고 있거나 이용할 수 있지만, 색상 픽셀들을 세 가지 다른 방법으로 배치합니다.
340
00:25:38,498 --> 00:25:43,023
모션 JPEG, MPEG-1 비디오, Theora와 WebM은 모두 색상 픽셀들을
341
00:25:43,023 --> 00:25:46,345
밝기 픽셀들의 수평과 수직 사이에 배치합니다.
342
00:25:46,345 --> 00:25:51,989
MPEG-2에서는 색상 채널들이 각 수평선 사이에 배치되지만, 수평적으로는 다른 밝기 픽셀들과 마찬가지로 정렬됩니다.
343
00:25:51,989 --> 00:25:57,106
인터레이싱 모드는 더 어렵게 만들고, 위치 배치를 좀 기괴하게 만듭니다.
344
00:25:57,106 --> 00:26:00,909
마지막으로 늘 인터레이싱을 하는 PAL-DV는 색상 채널들을
345
00:26:00,909 --> 00:26:04,398
수평 방향으로는 다른 밝기 픽셀들과 마찬가지 위치에 배치하고
346
00:26:04,398 --> 00:26:07,303
수직 방향으로는 각 선에서 색상 채널을 번갈아 가며 배치합니다.
347
00:26:07,683 --> 00:26:12,282
이것이 바로 4:2:0 비디오입니다.
다른 서브샘플링 방법들은 시청자분들의 숙제로 남겨두겠습니다.
348
00:26:12,282 --> 00:26:14,882
여러분은 기본 개념을 알게 되셨습니다. 계속하지요.
349
00:26:15,511 --> 00:26:21,128
오디오에서는 각 채널들의 샘플들을 순서대로 인터리빙하여 여러 채널들을 PCM 스트림에서 표현합니다.
350
00:26:21,128 --> 00:26:26,383
비디오는 색 채널들을 인터리빙하여 모아담는 방법과
351
00:26:26,383 --> 00:26:30,584
각 채널의 픽셀들을 프레임에 순서대로 쌓이는 각 평면들에 담는 평면적인 형식 두 개 모두 사용합니다.
352
00:26:30,584 --> 00:26:35,415
이 두 넓은 종류의 카테고리에 따라 최소 50개의 형식이 존재하는데
353
00:26:35,415 --> 00:26:41,549
그 중 10~15개 정도가 보통 쓰입니다. 각 색상 서브샘플링과 다른 비트 깊이는 다른 모아담는 방식을 요구하는데,
354
00:26:41,549 --> 00:26:46,574
이는 결국 다른 픽셀 형식을 요구합니다. 특별한 서브샘플링이 주어지면
355
00:26:46,574 --> 00:26:50,858 
사소한 채널 순서의 재배열이나 다른 방법으로 모아담는 여러 동일한 형식이 존재합니다.
356
00:26:50,858 --> 00:26:55,966
그러한 형식들의 존재 이유는 이전의 특별한 하드웨어에서의 편리함 때문일 수도 있고
357
00:26:55,966 --> 00:27:00,352
그냥 오래된 관습이라 그럴 수 있습니다.
358
00:27:00,352 --> 00:27:04,692
픽셀 형식들은 유일한 이름이나 fourcc 코드로 불립니다.
359
00:27:04,692 --> 00:27:08,115
여기 몇 개가 있는데, 지금 각각을 공부할 이유는 없네요.
360
00:27:08,115 --> 00:27:13,704
구글을 활용하세요. 본래 비디오를 위한 fourcc 코드는 픽셀 배열, 색상 서브샘플링을 특정하지만
361
00:27:13,704 --> 00:27:20,339
일반적으로 색상 픽셀의 실제 배치 위치나 색공간에 대해서는 설명하지 않음을 유의하세요.
362
00:27:20,339 --> 00:27:25,807
하나 예를 들자면, YV12 비디오는 JPEG, MPEG-2 또는 DV 색상 배치에 사용될 수 있고
363
00:27:25,807 --> 00:27:28,991
YUV 색공간 중 하나를 사용할 수 있습니다.
364
00:27:29,472 --> 00:27:33,913
이것으로 그리 빠르진 않은, 그리고 아직 아주 불완전한 본래 영상에 대한 여행을 마치겠습니다.
365
00:27:33,913 --> 00:27:38,651
좋은 소식은 우리는 이 개관을 통해서 실제 동영상에 대해 많이 배울 수 있었다는 것입니다.
366
00:27:38,651 --> 00:27:42,528
많은 상황에서, 비디오 데이터의 프레임은 그저 비디오 데이터의 프레임입니다.
367
00:27:42,528 --> 00:27:46,451
소프트웨어를 사용하게 되면 세부 사항들이 크게 중요해집니다.
368
00:27:46,452 --> 00:27:52,086
하지만 일단 지금 저는 존경하는 시청자들께서 관련된 논의점들을 넓게 알게 되셨다는 점에 만족합니다.
369
00:27:55,640 --> 00:27:59,230
자, 우리는 오디오 데이터도 갖고 있고, 비디오 데이터도 갖고 있네요.
370
00:27:59,230 --> 00:28:03,246
남은 것은 더 친숙한 비신호 데이터와 소프트웨어 개발자들에겐 익숙할 엔지니어링이네요.
371
00:28:03,246 --> 00:28:07,410
그리고 그게 아주 많아요!
372
00:28:07,928 --> 00:28:11,768 
본래 오디오와 비디오 데이터 조각들은 외적으로 보이는 구조가 없지만
373
00:28:11,768 -->  00:28:15,173
보통 일정한 크기로 만들어집니다. 우리는 이것들을 미리 정해진 순서로
374
00:28:15,173 --> 00:28:18,097
엄격하게 엮어서 스트리밍하거나 저장할 수 있고,
375
00:28:18,097 --> 00:28:21,040
어떤 시스템에서는 근사적으로 그렇게 합니다.
376
00:28:21,040 --> 00:28:24,195
압축된 프레임들은 반드시 정해진 크기를 가질 필요는 없고
377
00:28:24,195 --> 00:28:29,405
우리는 보통 스트림에서 여러 종류의 데이터를 다룰 때 어느 정도 유연성을 원합니다.
378
00:28:29,405 --> 00:28:34,281
형식이 없는 여러 데이터들을 같이 엮으면, 우리는 각 프레임들의 경계를 모르게 되고
379
00:28:34,281 --> 00:28:37,871
어느 데이터가 어느 스트림에 속하는지 모르게 됩니다.
380
00:28:37,871 --> 00:28:42,192
스트림이 널리 쓸모있으려면 어떤 일반화된 구조가 필요합니다.
381
00:28:42,192 --> 00:28:46,606
신호 데이터 외에도, PCM과 비디오 매개변수들이 있죠.
382
00:28:46,606 --> 00:28:49,752
아마도 우리가 다뤄야 할 많은 다른 메타데이터들이 있을 것입니다.
383
00:28:49,752 --> 00:28:55,415
오디오 태그, 비디오의 각 장과 자막과 같은 리치 미디어의 필수 요소들이죠.
384
00:28:55,415 --> 00:29:01,633
미디어 자체에 데이터에 데한 데이터, 즉 메타데이터를 담는 것이 합리적입니다.
385
00:29:01,633 --> 00:29:06,445
형식이 없는 데이터와 이질적인 메타데이터를 저장하고 구조화하는 것은 컨테이너의 역할입니다.
386
00:29:06,445 --> 00:29:09,221
컨테이너는 데이터 덩어리들을 프레임화하고
387
00:29:09,221 --> 00:29:12,015
여러 데이터 스트림들을 인터리브하고 판별하고
388
00:29:12,015 --> 00:29:15,337
시간 정보와 미디어를 해석하고, 시간에 따라 탐색하고, 조작하고, 재생하는 데 필요한
389
00:29:15,337 --> 00:29:19,140
메타데이터를 저장하는 역할을 합니다.
390
00:29:19,140 --> 00:29:22,222
일반적으로, 모든 컨테이너는 모든 종류의 데이터를 담을 수 있습니다.
391
00:29:22,222 --> 00:29:24,970
그리고 데이터는 모든 컨테이너 안에 모일 수 있죠.
392
00:29:28,801 --> 00:29:32,391 
지난 30분 동안, 우리는 디지털 오디오, 비디오,
393
00:29:32,391 --> 00:29:35,435
역사 조금, 수학 조금과 엔지니어링 조금을 다뤘습니다.
394
00:29:35,435 --> 00:29:39,377
우리는 간신히 겉핥기만 했지만, 이제 멈출 시간이네요.
395
00:29:41,107 --> 00:29:45,373
얘기할 게 엄청 많으니, 다음 영상에서 또 만나길 바랄게요.
396
00:29:45,373 --> 00:29:47,159
그때까지, 화이팅!
